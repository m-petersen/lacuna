{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6a82791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "\n",
    "# Import core types\n",
    "from lacuna import MaskData\n",
    "from lacuna.core import VoxelMap, ParcelData, ConnectivityMatrix, ScalarMetric\n",
    "\n",
    "# Import analyses\n",
    "from lacuna.analysis import (\n",
    "    FunctionalNetworkMapping,\n",
    "    StructuralNetworkMapping,\n",
    "    RegionalDamage,\n",
    "    ParcelAggregation,\n",
    ")\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207fad30",
   "metadata": {},
   "source": [
    "## 1. Creating MaskData (formerly LesionData)\n",
    "\n",
    "MaskData now supports multiple input methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11139616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic mask data\n",
    "shape = (91, 109, 91)\n",
    "affine = np.diag([2.0, 2.0, 2.0, 1.0])\n",
    "\n",
    "# Binary mask (enforced in v0.5.0)\n",
    "mask_array = np.zeros(shape, dtype=np.uint8)\n",
    "mask_array[40:50, 50:60, 40:50] = 1  # Lesion region\n",
    "\n",
    "mask_img = nib.Nifti1Image(mask_array, affine)\n",
    "\n",
    "# Method 1: From nibabel image (NEW in v0.5.0)\n",
    "mask_data = MaskData(\n",
    "    mask_img=mask_img,\n",
    "    metadata={\n",
    "        \"space\": \"MNI152NLin6Asym\",\n",
    "        \"resolution\": 2.0,\n",
    "        \"subject_id\": \"demo_001\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Created MaskData: {mask_data.space} @ {mask_data.resolution}mm\")\n",
    "print(f\"Mask volume: {mask_data.get_volume_mm3():.1f} mm³\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd954c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: From file path (classic method)\n",
    "# Create temporary file\n",
    "import tempfile\n",
    "tmp_dir = Path(tempfile.mkdtemp())\n",
    "mask_path = tmp_dir / \"test_mask.nii.gz\"\n",
    "nib.save(mask_img, mask_path)\n",
    "\n",
    "mask_data_from_file = MaskData.from_nifti(\n",
    "    lesion_path=mask_path,\n",
    "    metadata={\n",
    "        \"space\": \"MNI152NLin6Asym\",\n",
    "        \"resolution\": 2.0\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Loaded MaskData from file: {mask_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36573acd",
   "metadata": {},
   "source": [
    "## 2. Binary Mask Validation (NEW in v0.5.0)\n",
    "\n",
    "Masks must now contain only 0 and 1 values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9c1039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This would fail - continuous values not allowed\n",
    "try:\n",
    "    bad_mask = np.random.rand(*shape)\n",
    "    bad_mask_img = nib.Nifti1Image(bad_mask.astype(np.float32), affine)\n",
    "    MaskData(\n",
    "        mask_img=bad_mask_img,\n",
    "        metadata={\"space\": \"MNI152NLin6Asym\", \"resolution\": 2.0}\n",
    "    )\n",
    "except ValueError as e:\n",
    "    print(f\"✓ Validation caught non-binary mask: {e}\")\n",
    "\n",
    "# Binarization example\n",
    "continuous_mask = np.random.rand(*shape)\n",
    "binary_mask = (continuous_mask > 0.5).astype(np.uint8)\n",
    "print(f\"\\nBinarized mask: {np.sum(binary_mask)} voxels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080363b4",
   "metadata": {},
   "source": [
    "## 3. Functional Network Mapping\n",
    "\n",
    "Returns unified VoxelMap containers (formerly VoxelMapResult):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b7aebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This requires a registered functional connectome\n",
    "# For demo purposes, we'll show the API structure\n",
    "\n",
    "fnm = FunctionalNetworkMapping(\n",
    "    connectome=\"GSP1000\",  # Example connectome\n",
    "    method=\"correlation\",\n",
    "    log_level=\"INFO\"  # NEW: Control logging output\n",
    ")\n",
    "\n",
    "print(f\"Analysis: {fnm}\")\n",
    "print(f\"\\nConnectome: {fnm.connectome}\")\n",
    "print(f\"Method: {fnm.method}\")\n",
    "\n",
    "# Run analysis (commented out - requires actual connectome)\n",
    "# result = fnm.run(mask_data)\n",
    "# print(f\"\\nResults: {list(result.results['FunctionalNetworkMapping'].keys())}\")\n",
    "# correlation_map = result.results['FunctionalNetworkMapping']['correlation_map_from_mask_img']\n",
    "# print(f\"Type: {type(correlation_map)}  # VoxelMap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b1461b",
   "metadata": {},
   "source": [
    "## 4. Regional Damage Analysis\n",
    "\n",
    "Returns ParcelData containers (formerly ROIResult) with atlas-based damage percentages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40907f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regional damage uses bundled atlases\n",
    "regional = RegionalDamage(\n",
    "    parcel_names=[\"Schaefer100\", \"Schaefer200\"],  # Filter specific atlases\n",
    "    threshold=0.0,\n",
    "    log_level=\"WARNING\"  # Quieter logging\n",
    ")\n",
    "\n",
    "result = regional.run(mask_data)\n",
    "\n",
    "# Access results - dict with atlas names as keys\n",
    "damage_results = result.results[\"RegionalDamage\"]\n",
    "print(f\"Atlases processed: {list(damage_results.keys())}\")\n",
    "\n",
    "# Each atlas returns ParcelData\n",
    "for atlas_key, parcel_data in damage_results.items():\n",
    "    print(f\"\\n{atlas_key}:\")\n",
    "    print(f\"  Type: {type(parcel_data).__name__}\")  # ParcelData\n",
    "    print(f\"  Regions: {len(parcel_data.get_data())}\")\n",
    "    \n",
    "    # Get damage percentages\n",
    "    damage_dict = parcel_data.get_data()\n",
    "    damaged_regions = {k: v for k, v in damage_dict.items() if v > 0}\n",
    "    print(f\"  Damaged regions: {len(damaged_regions)}\")\n",
    "    \n",
    "    # Show top 3 most damaged\n",
    "    top_damaged = sorted(damaged_regions.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "    for region, pct in top_damaged:\n",
    "        print(f\"    {region}: {pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3e2886",
   "metadata": {},
   "source": [
    "## 5. Parcel Aggregation (formerly AtlasAggregation)\n",
    "\n",
    "Aggregate VoxelMap data by atlas parcels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff970cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create a VoxelMap to aggregate\n",
    "# For demo, create synthetic connectivity map\n",
    "correlation_data = np.random.randn(*shape).astype(np.float32)\n",
    "correlation_img = nib.Nifti1Image(correlation_data, affine)\n",
    "\n",
    "correlation_map = VoxelMap(\n",
    "    name=\"correlation_map\",\n",
    "    data=correlation_img,\n",
    "    space=\"MNI152NLin6Asym\",\n",
    "    resolution=2.0,\n",
    "    metadata={\"method\": \"correlation\", \"connectome\": \"demo\"}\n",
    ")\n",
    "\n",
    "print(f\"Created VoxelMap: {correlation_map.name}\")\n",
    "print(f\"  Space: {correlation_map.space}\")\n",
    "print(f\"  Resolution: {correlation_map.resolution}mm\")\n",
    "\n",
    "# Add to MaskData results\n",
    "mask_data.results[\"DemoAnalysis\"] = {\"correlation_map\": correlation_map}\n",
    "\n",
    "# Now aggregate by atlas\n",
    "aggregation = ParcelAggregation(\n",
    "    source=\"DemoAnalysis.correlation_map\",  # Cross-analysis reference\n",
    "    aggregation=\"mean\",\n",
    "    parcel_names=[\"Schaefer100\"],\n",
    "    threshold=0.0\n",
    ")\n",
    "\n",
    "agg_result = aggregation.run(mask_data)\n",
    "parcel_data = agg_result.results[\"ParcelAggregation\"][\"Schaefer100_from_correlation_map\"]\n",
    "\n",
    "print(f\"\\nAggregated to {len(parcel_data.get_data())} parcels\")\n",
    "print(f\"Aggregation method: {parcel_data.aggregation_method}\")\n",
    "\n",
    "# Show sample values\n",
    "sample_parcels = list(parcel_data.get_data().items())[:5]\n",
    "for parcel, value in sample_parcels:\n",
    "    print(f\"  {parcel}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca29db2",
   "metadata": {},
   "source": [
    "## 6. Data Container Features\n",
    "\n",
    "All unified containers share common functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f86126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata storage\n",
    "print(f\"VoxelMap metadata: {correlation_map.metadata}\")\n",
    "\n",
    "# Summary strings\n",
    "print(f\"\\nVoxelMap summary: {correlation_map.summary()}\")\n",
    "print(f\"ParcelData summary: {parcel_data.summary()}\")\n",
    "\n",
    "# Data access\n",
    "print(f\"\\nVoxelMap data type: {type(correlation_map.get_data())}\")\n",
    "print(f\"ParcelData data type: {type(parcel_data.get_data())}\")\n",
    "\n",
    "# Container type identification\n",
    "print(f\"\\nContainer types:\")\n",
    "print(f\"  VoxelMap: {correlation_map.data_type}\")\n",
    "print(f\"  ParcelData: {parcel_data.data_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b0b0d5",
   "metadata": {},
   "source": [
    "## 7. ScalarMetric for Summary Statistics\n",
    "\n",
    "Store scalars, dictionaries, or any other data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c865a103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scalar value\n",
    "mean_corr = ScalarMetric(\n",
    "    name=\"mean_correlation\",\n",
    "    data=0.42,\n",
    "    metadata={\"units\": \"Pearson r\"}\n",
    ")\n",
    "\n",
    "print(f\"Scalar: {mean_corr.summary()}\")\n",
    "print(f\"Data type: {mean_corr.data_type}\")  # Inferred as \"scalar\"\n",
    "\n",
    "# Dictionary of stats\n",
    "summary_stats = ScalarMetric(\n",
    "    name=\"summary_statistics\",\n",
    "    data={\n",
    "        \"mean\": 0.42,\n",
    "        \"std\": 0.15,\n",
    "        \"min\": -0.3,\n",
    "        \"max\": 0.9,\n",
    "        \"n_voxels\": 1000\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"\\nDictionary: {summary_stats.summary()}\")\n",
    "print(f\"Data type: {summary_stats.data_type}\")  # Inferred as \"dictionary\"\n",
    "\n",
    "# Custom type label\n",
    "custom_metric = ScalarMetric(\n",
    "    name=\"lesion_severity\",\n",
    "    data=\"moderate\",\n",
    "    data_type=\"categorical\"  # Explicit type\n",
    ")\n",
    "\n",
    "print(f\"\\nCustom: {custom_metric.summary()}\")\n",
    "print(f\"Data type: {custom_metric.data_type}\")  # Uses provided type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54beb70b",
   "metadata": {},
   "source": [
    "## 8. Input/Output Symmetry (US6)\n",
    "\n",
    "Containers work as both inputs and outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37063632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a VoxelMap as input\n",
    "input_map = VoxelMap(\n",
    "    name=\"input_connectivity\",\n",
    "    data=correlation_img,\n",
    "    space=\"MNI152NLin6Asym\",\n",
    "    resolution=2.0\n",
    ")\n",
    "\n",
    "# Use it as input to ParcelAggregation\n",
    "# (Store in MaskData first)\n",
    "mask_data.results[\"InputTest\"] = {\"input_map\": input_map}\n",
    "\n",
    "aggregation = ParcelAggregation(\n",
    "    source=\"InputTest.input_map\",\n",
    "    aggregation=\"mean\",\n",
    "    parcel_names=[\"Schaefer100\"]\n",
    ")\n",
    "\n",
    "output = aggregation.run(mask_data)\n",
    "\n",
    "# Get ParcelData output\n",
    "output_parcel = output.results[\"ParcelAggregation\"][\"Schaefer100_from_input_map\"]\n",
    "\n",
    "print(f\"Input container: {type(input_map).__name__}\")\n",
    "print(f\"Output container: {type(output_parcel).__name__}\")\n",
    "print(f\"\\n✓ Same container types used for input and output!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbd5065",
   "metadata": {},
   "source": [
    "## 9. Logging Control\n",
    "\n",
    "All analyses support log_level parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c32bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiet mode - only errors\n",
    "quiet_analysis = RegionalDamage(\n",
    "    parcel_names=[\"Schaefer100\"],\n",
    "    log_level=\"ERROR\"\n",
    ")\n",
    "\n",
    "print(\"Running with ERROR logging (should be quiet):\")\n",
    "result_quiet = quiet_analysis.run(mask_data)\n",
    "print(\"Done (minimal output)\\n\")\n",
    "\n",
    "# Verbose mode - detailed information\n",
    "verbose_analysis = RegionalDamage(\n",
    "    parcel_names=[\"Schaefer100\"],\n",
    "    log_level=\"DEBUG\"\n",
    ")\n",
    "\n",
    "print(\"Running with DEBUG logging (verbose):\")\n",
    "result_verbose = verbose_analysis.run(mask_data)\n",
    "print(\"Done (detailed output)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab076b8",
   "metadata": {},
   "source": [
    "## 10. Migration Summary\n",
    "\n",
    "### Key Changes in v0.5.0\n",
    "\n",
    "| Old API (v0.4.x) | New API (v0.5.0) |\n",
    "|------------------|------------------|\n",
    "| `from lacuna import LesionData` | `from lacuna import MaskData` |\n",
    "| `LesionData(...)` | `MaskData(...)` |\n",
    "| `VoxelMapResult` | `VoxelMap` |\n",
    "| `ROIResult` | `ParcelData` |\n",
    "| `AtlasAggregation` | `ParcelAggregation` |\n",
    "| `anatomical_img` parameter | Removed (not needed) |\n",
    "| Continuous masks allowed | Only binary (0/1) masks |\n",
    "\n",
    "### New Features\n",
    "\n",
    "- ✨ Direct nibabel input support\n",
    "- ✨ Logging control via `log_level`\n",
    "- ✨ Binary mask validation\n",
    "- ✨ Input/output symmetry (US6)\n",
    "- ✨ Unified container API\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- See `docs/migration_guide.md` for complete migration instructions\n",
    "- Check `examples/` for more usage patterns\n",
    "- Run `make test` to verify your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd80143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "import shutil\n",
    "shutil.rmtree(tmp_dir)\n",
    "print(\"Cleaned up temporary files\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lacuna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
